{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WkaYn23CBqY"
      },
      "source": [
        "# Import libraries and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFv42jjQgwTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b46c8dd7-d0e7-422c-f70d-a0a69014aed6"
      },
      "source": [
        "## install finrl library\n",
        "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
            "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to /tmp/pip-req-build-3xz7m63p\n",
            "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-3xz7m63p\n",
            "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
            "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-xndlpr4q/pyfolio_044ae4928be04ddb95a4ae3745ac9ea2\n",
            "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-xndlpr4q/pyfolio_044ae4928be04ddb95a4ae3745ac9ea2\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-xndlpr4q/elegantrl_d0159ca6828b4ef0a9ffd95e85589946\n",
            "  Running command git clone -q https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-xndlpr4q/elegantrl_d0159ca6828b4ef0a9ffd95e85589946\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.19.5)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.1.5)\n",
            "Requirement already satisfied: stockstats in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.3.2)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.1.66)\n",
            "Requirement already satisfied: elegantrl in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.0.1)\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.17.3)\n",
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.3.0)\n",
            "Requirement already satisfied: ray[default] in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.8.0)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.1.3)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (2.4)\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.4.0)\n",
            "Requirement already satisfied: trading_calendars in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (2.1.1)\n",
            "Requirement already satisfied: alpaca_trade_api in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.4.1)\n",
            "Requirement already satisfied: ccxt in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.61.40)\n",
            "Requirement already satisfied: jqdatasdk in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.8.10)\n",
            "Requirement already satisfied: wrds in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.1.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.6.4)\n",
            "Requirement already satisfied: setuptools>=41.4.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.37.0)\n",
            "Requirement already satisfied: pre-commit in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (2.15.0)\n",
            "Requirement already satisfied: pybullet in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (3.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (1.10.0+cu111)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (4.1.2.30)\n",
            "Requirement already satisfied: box2d-py in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (2.3.8)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.5.0)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2018.9)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.4.1)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.11.2)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.5.5)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.5.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.1.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (2.4.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.23.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.6.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.2.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.3.3) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2021.10.8)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (3.0.0)\n",
            "Requirement already satisfied: aiohttp==3.7.4 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api->finrl==0.3.3) (3.7.4)\n",
            "Requirement already satisfied: websockets<10,>=8.0 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api->finrl==0.3.3) (9.1)\n",
            "Requirement already satisfied: msgpack==1.0.2 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api->finrl==0.3.3) (1.0.2)\n",
            "Requirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api->finrl==0.3.3) (1.2.1)\n",
            "Requirement already satisfied: PyYAML==5.4.1 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api->finrl==0.3.3) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (3.10.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (5.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (1.6.3)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (3.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (21.2.0)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from ccxt->finrl==0.3.3) (35.0.0)\n",
            "Requirement already satisfied: aiodns>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from ccxt->finrl==0.3.3) (3.0.0)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from aiodns>=1.1.1->ccxt->finrl==0.3.3) (4.1.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt->finrl==0.3.3) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt->finrl==0.3.3) (2.21)\n",
            "Requirement already satisfied: thriftpy2>=0.3.9 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.3) (0.4.14)\n",
            "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.3) (1.4.26)\n",
            "Requirement already satisfied: pymysql>=0.7.6 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.3) (1.0.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (4.8.2)\n",
            "Requirement already satisfied: ply<4.0,>=3.4 in /usr/local/lib/python3.7/dist-packages (from thriftpy2>=0.3.9->jqdatasdk->finrl==0.3.3) (3.11)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (3.6.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (2.3.6)\n",
            "Requirement already satisfied: virtualenv>=20.0.8 in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (20.10.0)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (1.6.0)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (3.3.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (0.10.2)\n",
            "Requirement already satisfied: backports.entry-points-selectable>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (1.1.1)\n",
            "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (3.3.2)\n",
            "Requirement already satisfied: platformdirs<3,>=2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (2.4.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (0.3.3)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (8.11.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.11.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (2.6.0)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.41.1)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (3.17.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (7.1.2)\n",
            "Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (4.0.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.5.4)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.8.0)\n",
            "Requirement already satisfied: aioredis<2 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.3.1)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.3.11)\n",
            "Requirement already satisfied: gpustat>=1.0.0b1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.0.0b1)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.12.0)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.7.0)\n",
            "Requirement already satisfied: hiredis in /usr/local/lib/python3.7/dist-packages (from aioredis<2->ray[default]->finrl==0.3.3) (2.0.0)\n",
            "Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (1.19.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (7.352.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (5.4.8)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]->finrl==0.3.3) (1.2.13)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated->redis>=3.5.0->ray[default]->finrl==0.3.3) (1.13.3)\n",
            "Requirement already satisfied: opencensus-context==0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.3) (0.1.2)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.3) (1.26.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.53.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (21.2)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.2.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.4.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.8.9)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (2.7.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (0.2.9)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (7.1.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.3.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.12.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.1.1)\n",
            "Requirement already satisfied: int-date>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from stockstats->finrl==0.3.3) (0.1.8)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from trading_calendars->finrl==0.3.3) (0.11.2)\n",
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.7/dist-packages (from wrds->finrl==0.3.3) (2.9.2)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.7/dist-packages (from wrds->finrl==0.3.3) (4.0.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.3) (0.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-djUkcDrg1jb",
        "outputId": "954d5c61-73f6-4102-dfae-fffbcbae9598"
      },
      "source": [
        "## import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "%matplotlib inline\n",
        "import datetime\n",
        "import calendar\n",
        "\n",
        "from finrl.apps import config\n",
        "from finrl.neo_finrl.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.neo_finrl.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.neo_finrl.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
        "from finrl.drl_agents.stablebaselines3.models import DRLAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")\n",
        "\n",
        "import os\n",
        "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
        "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
        "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
        "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
        "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
        "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
        "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
        "    os.makedirs(\"./\" + config.RESULTS_DIR)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
            "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZoHtxAYf_VC"
      },
      "source": [
        "# URL to git repo\n",
        "url = 'https://github.com/changjulian17/DataSciencePortfolio/blob/main/Investment_Portfolio/data/processed_data.pkl?raw=true'\n",
        "df = pd.read_pickle(url)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMQD9E-Wf_i3"
      },
      "source": [
        "# Design Environment\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a Markov Decision Process (MDP) problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTChtMG7kzmf"
      },
      "source": [
        "## Training data split 2005-11-30 to 2020-01-01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r04T6g-ggwHL"
      },
      "source": [
        "train = data_split(df, '2005-11-30','2020-01-01')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQJ14wNzQ15j",
        "outputId": "b9b9b1d6-43b2-475e-e2a9-13faf9fae50d"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24801, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CswmBNls19MI",
        "outputId": "8616a396-5ca2-4ef9-feee-01c6940d1f40"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>cov_list</th>\n",
              "      <th>return_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27736</th>\n",
              "      <td>2021-08-31</td>\n",
              "      <td>52.470001</td>\n",
              "      <td>52.520000</td>\n",
              "      <td>52.330002</td>\n",
              "      <td>52.410000</td>\n",
              "      <td>43226700.0</td>\n",
              "      <td>EEM</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.276504</td>\n",
              "      <td>53.255365</td>\n",
              "      <td>49.519635</td>\n",
              "      <td>49.906189</td>\n",
              "      <td>78.207188</td>\n",
              "      <td>6.277385</td>\n",
              "      <td>51.614666</td>\n",
              "      <td>53.012122</td>\n",
              "      <td>[[4.1802741524284105e-06, -1.8829709541513621e...</td>\n",
              "      <td>tic              AGG       COM       EEM  ... ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27737</th>\n",
              "      <td>2021-08-31</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>630.590000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>GLD</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.496968</td>\n",
              "      <td>637.901073</td>\n",
              "      <td>600.379927</td>\n",
              "      <td>52.402475</td>\n",
              "      <td>83.613562</td>\n",
              "      <td>6.277385</td>\n",
              "      <td>622.136000</td>\n",
              "      <td>626.241500</td>\n",
              "      <td>[[4.1802741524284105e-06, -1.8829709541513621e...</td>\n",
              "      <td>tic              AGG       COM       EEM  ... ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27738</th>\n",
              "      <td>2021-08-31</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>117.489998</td>\n",
              "      <td>117.120003</td>\n",
              "      <td>116.926025</td>\n",
              "      <td>7418400.0</td>\n",
              "      <td>IEF</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.076884</td>\n",
              "      <td>117.821486</td>\n",
              "      <td>116.121367</td>\n",
              "      <td>53.687664</td>\n",
              "      <td>-14.855131</td>\n",
              "      <td>7.496965</td>\n",
              "      <td>117.068840</td>\n",
              "      <td>116.272461</td>\n",
              "      <td>[[4.1802741524284105e-06, -1.8829709541513621e...</td>\n",
              "      <td>tic              AGG       COM       EEM  ... ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27739</th>\n",
              "      <td>2021-08-31</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>190.572196</td>\n",
              "      <td>0.0</td>\n",
              "      <td>LOV</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.400142</td>\n",
              "      <td>190.572203</td>\n",
              "      <td>190.572189</td>\n",
              "      <td>1.183841</td>\n",
              "      <td>-45.454545</td>\n",
              "      <td>7.496965</td>\n",
              "      <td>191.162715</td>\n",
              "      <td>192.190168</td>\n",
              "      <td>[[4.1802741524284105e-06, -1.8829709541513621e...</td>\n",
              "      <td>tic              AGG       COM       EEM  ... ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27740</th>\n",
              "      <td>2021-08-31</td>\n",
              "      <td>9448.330078</td>\n",
              "      <td>9451.559570</td>\n",
              "      <td>9419.410156</td>\n",
              "      <td>9433.580078</td>\n",
              "      <td>0.0</td>\n",
              "      <td>SNP</td>\n",
              "      <td>1.0</td>\n",
              "      <td>77.304140</td>\n",
              "      <td>9458.550010</td>\n",
              "      <td>9131.839053</td>\n",
              "      <td>62.965117</td>\n",
              "      <td>167.127295</td>\n",
              "      <td>21.356673</td>\n",
              "      <td>9250.471322</td>\n",
              "      <td>9087.068766</td>\n",
              "      <td>[[4.1802741524284105e-06, -1.8829709541513621e...</td>\n",
              "      <td>tic              AGG       COM       EEM  ... ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             date  ...                                        return_list\n",
              "27736  2021-08-31  ...  tic              AGG       COM       EEM  ... ...\n",
              "27737  2021-08-31  ...  tic              AGG       COM       EEM  ... ...\n",
              "27738  2021-08-31  ...  tic              AGG       COM       EEM  ... ...\n",
              "27739  2021-08-31  ...  tic              AGG       COM       EEM  ... ...\n",
              "27740  2021-08-31  ...  tic              AGG       COM       EEM  ... ...\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OBdBmX7kk_Y"
      },
      "source": [
        "## Environment for Portfolio Allocation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XAX0FudgvwZ"
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "\n",
        "class StockPortfolioEnv(gym.Env):\n",
        "    \"\"\"A single stock trading environment for OpenAI gym\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        df: DataFrame\n",
        "            input data\n",
        "        stock_dim : int\n",
        "            number of unique stocks\n",
        "        hmax : int\n",
        "            maximum number of shares to trade\n",
        "        initial_amount : int\n",
        "            start money\n",
        "        transaction_cost_pct: float\n",
        "            transaction cost percentage per trade\n",
        "        reward_scaling: float\n",
        "            scaling factor for reward, good for training\n",
        "        state_space: int\n",
        "            the dimension of input features\n",
        "        action_space: int\n",
        "            equals stock dimension\n",
        "        tech_indicator_list: list\n",
        "            a list of technical indicator names\n",
        "        turbulence_threshold: int\n",
        "            a threshold to control risk aversion\n",
        "        day: int\n",
        "            an increment number to control date\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    _sell_stock()\n",
        "        perform sell action based on the sign of the action\n",
        "    _buy_stock()\n",
        "        perform buy action based on the sign of the action\n",
        "    step()\n",
        "        at each step the agent will return actions, then \n",
        "        we will calculate the reward, and return the next observation.\n",
        "    reset()\n",
        "        reset the environment\n",
        "    render()\n",
        "        use render to return other functions\n",
        "    save_asset_memory()\n",
        "        return account value at each time step\n",
        "    save_action_memory()\n",
        "        return actions/positions at each time step\n",
        "        \n",
        "\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, \n",
        "                df,\n",
        "                stock_dim,\n",
        "                hmax,\n",
        "                initial_amount,\n",
        "                transaction_cost_pct,\n",
        "                reward_scaling,\n",
        "                state_space,\n",
        "                action_space,\n",
        "                tech_indicator_list,\n",
        "                turbulence_threshold=None,\n",
        "                lookback=252,\n",
        "                day = 0):\n",
        "        #super(StockEnv, self).__init__()\n",
        "        #money = 10 , scope = 1\n",
        "        self.day = day\n",
        "        self.lookback=lookback\n",
        "        self.df = df\n",
        "        self.stock_dim = stock_dim\n",
        "        self.hmax = hmax\n",
        "        self.initial_amount = initial_amount\n",
        "        self.transaction_cost_pct =transaction_cost_pct\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "\n",
        "        # action_space normalization and shape is self.stock_dim\n",
        "        self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,)) \n",
        "        # Shape = (34, 30)\n",
        "        # covariance matrix + technical indicators\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (self.state_space+len(self.tech_indicator_list),self.state_space))\n",
        "\n",
        "        # load data from a pandas dataframe\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "        self.terminal = False     \n",
        "        self.turbulence_threshold = turbulence_threshold        \n",
        "        # initalize state: inital portfolio return + individual stock return + individual weights\n",
        "        self.portfolio_value = self.initial_amount\n",
        "\n",
        "        # memorize portfolio value each step\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        # memorize portfolio return each step\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.date.unique()[0]]\n",
        "\n",
        "        \n",
        "    def step(self, actions):\n",
        "        # print(self.day)\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "        # print(actions)\n",
        "\n",
        "        if self.terminal:\n",
        "            df = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df.columns = ['daily_return']\n",
        "            plt.plot(df.daily_return.cumsum(),'r')\n",
        "            plt.savefig('results/cumulative_reward.png')\n",
        "            plt.close()\n",
        "            \n",
        "            plt.plot(self.portfolio_return_memory,'r')\n",
        "            plt.savefig('results/rewards.png')\n",
        "            plt.close()\n",
        "\n",
        "            print(\"=================================\")\n",
        "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))           \n",
        "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
        "\n",
        "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df_daily_return.columns = ['daily_return']\n",
        "            if df_daily_return['daily_return'].std() !=0:\n",
        "              sharpe = (252**0.5)*df_daily_return['daily_return'].mean()/ \\\n",
        "                       df_daily_return['daily_return'].std()\n",
        "              print(\"Sharpe: \",sharpe)\n",
        "            print(\"=================================\")\n",
        "            \n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            #print(\"Model actions: \",actions)\n",
        "            # actions are the portfolio weight\n",
        "            # normalize to sum of 1\n",
        "            #if (np.array(actions) - np.array(actions).min()).sum() != 0:\n",
        "            #  norm_actions = (np.array(actions) - np.array(actions).min()) / (np.array(actions) - np.array(actions).min()).sum()\n",
        "            #else:\n",
        "            #  norm_actions = actions\n",
        "            weights = self.softmax_normalization(actions) \n",
        "            #print(\"Normalized actions: \", weights)\n",
        "            self.actions_memory.append(weights)\n",
        "            last_day_memory = self.data\n",
        "\n",
        "            #load next state\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day,:]\n",
        "            self.covs = self.data['cov_list'].values[0]\n",
        "            self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "            #print(self.state)\n",
        "            # calcualte portfolio return\n",
        "            # individual stocks' return * weight\n",
        "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values)-1)*weights)\n",
        "            # update portfolio value\n",
        "            new_portfolio_value = self.portfolio_value*(1+portfolio_return)\n",
        "            self.portfolio_value = new_portfolio_value\n",
        "\n",
        "            # save into memory\n",
        "            self.portfolio_return_memory.append(portfolio_return)\n",
        "            self.date_memory.append(self.data.date.unique()[0])            \n",
        "            self.asset_memory.append(new_portfolio_value)\n",
        "\n",
        "            # the reward is the new portfolio value or end portfolo value\n",
        "            self.reward = new_portfolio_value \n",
        "            #print(\"Step reward: \", self.reward)\n",
        "            #self.reward = self.reward*self.reward_scaling\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        # load states\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "        self.portfolio_value = self.initial_amount\n",
        "        #self.cost = 0\n",
        "        #self.trades = 0\n",
        "        self.terminal = False \n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.date.unique()[0]] \n",
        "        return self.state\n",
        "    \n",
        "    def render(self, mode='human'):\n",
        "        return self.state\n",
        "        \n",
        "    def softmax_normalization(self, actions):\n",
        "        numerator = np.exp(actions)\n",
        "        denominator = np.sum(np.exp(actions))\n",
        "        softmax_output = numerator/denominator\n",
        "        return softmax_output\n",
        "\n",
        "    \n",
        "    def save_asset_memory(self):\n",
        "        date_list = self.date_memory\n",
        "        portfolio_return = self.portfolio_return_memory\n",
        "        #print(len(date_list))\n",
        "        #print(len(asset_list))\n",
        "        df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
        "        return df_account_value\n",
        "\n",
        "    def save_action_memory(self):\n",
        "        # date and close price length must match actions length\n",
        "        date_list = self.date_memory\n",
        "        df_date = pd.DataFrame(date_list)\n",
        "        df_date.columns = ['date']\n",
        "        \n",
        "        action_list = self.actions_memory\n",
        "        df_actions = pd.DataFrame(action_list)\n",
        "        df_actions.columns = self.data.tic.values\n",
        "        df_actions.index = df_date.date\n",
        "        #df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
        "        return df_actions\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def get_sb_env(self):\n",
        "        e = DummyVecEnv([lambda: self])\n",
        "        obs = e.reset()\n",
        "        return e, obs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK1ZpYBBlLVh",
        "outputId": "e4ccb12c-7e02-4a89-b69f-dfc51dfcd333"
      },
      "source": [
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 7, State Space: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsWY2c3ilK7B"
      },
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100, \n",
        "    \"initial_amount\": 1000000, \n",
        "    \"transaction_cost_pct\": 0.001, \n",
        "    \"state_space\": state_space, \n",
        "    \"stock_dim\": stock_dimension, \n",
        "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
        "    \"action_space\": stock_dimension, \n",
        "    \"reward_scaling\": 1e-4\n",
        "    \n",
        "}\n",
        "\n",
        "e_train_gym = StockPortfolioEnv(df = train, **env_kwargs)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTivilQplQCO",
        "outputId": "6b0ac775-a665-44fe-826c-8ee67a4702f5"
      },
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-Za6eCMaEQT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYiROCrXxfpB"
      },
      "source": [
        "# Model PPO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veLW6P8Bjtqk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydze26bfm5P6",
        "outputId": "9b370766-c9a7-4a8d-c2d3-052eef70b672"
      },
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "PPO_PARAMS = {\n",
        "    \"n_steps\": 2048,\n",
        "    \"ent_coef\": 0.005,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"batch_size\": 128,\n",
        "}\n",
        "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.0001, 'batch_size': 128}\n",
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiVh44fkxhw4",
        "outputId": "6d4002a3-ec6a-4fe9-b3f0-634b2bdfd619"
      },
      "source": [
        "trained_ppo = agent.train_model(model=model_ppo, \n",
        "                             tb_log_name='ppo',\n",
        "                             total_timesteps=1280000)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.28e+14  |\n",
            "|    n_updates            | 4060      |\n",
            "|    policy_gradient_loss | -2.55e-07 |\n",
            "|    reward               | 1353987.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.04e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 426       |\n",
            "|    iterations           | 408       |\n",
            "|    time_elapsed         | 1959      |\n",
            "|    total_timesteps      | 835584    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -3.58e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.54e+14  |\n",
            "|    n_updates            | 4070      |\n",
            "|    policy_gradient_loss | -1.74e-07 |\n",
            "|    reward               | 2050178.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.28e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2330078.388508283\n",
            "Sharpe:  0.7290732966872246\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 426       |\n",
            "|    iterations           | 409       |\n",
            "|    time_elapsed         | 1964      |\n",
            "|    total_timesteps      | 837632    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.78e+14  |\n",
            "|    n_updates            | 4080      |\n",
            "|    policy_gradient_loss | -1.37e-07 |\n",
            "|    reward               | 1604568.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.49e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 426       |\n",
            "|    iterations           | 410       |\n",
            "|    time_elapsed         | 1969      |\n",
            "|    total_timesteps      | 839680    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.36e+14  |\n",
            "|    n_updates            | 4090      |\n",
            "|    policy_gradient_loss | -3.63e-07 |\n",
            "|    reward               | 1946934.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.81e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1963085.6581540504\n",
            "Sharpe:  0.584329709750899\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 426       |\n",
            "|    iterations           | 411       |\n",
            "|    time_elapsed         | 1973      |\n",
            "|    total_timesteps      | 841728    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.3e+14   |\n",
            "|    n_updates            | 4100      |\n",
            "|    policy_gradient_loss | -2.77e-07 |\n",
            "|    reward               | 1581306.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.33e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1899711.9581207188\n",
            "Sharpe:  0.5668390494521529\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 426       |\n",
            "|    iterations           | 412       |\n",
            "|    time_elapsed         | 1979      |\n",
            "|    total_timesteps      | 843776    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.67e+14  |\n",
            "|    n_updates            | 4110      |\n",
            "|    policy_gradient_loss | -7.69e-08 |\n",
            "|    reward               | 1281231.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.25e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 426       |\n",
            "|    iterations           | 413       |\n",
            "|    time_elapsed         | 1984      |\n",
            "|    total_timesteps      | 845824    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.38e+14  |\n",
            "|    n_updates            | 4120      |\n",
            "|    policy_gradient_loss | -2.04e-07 |\n",
            "|    reward               | 1718564.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.67e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2085863.9820633887\n",
            "Sharpe:  0.6319752905434028\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 425       |\n",
            "|    iterations           | 414       |\n",
            "|    time_elapsed         | 1990      |\n",
            "|    total_timesteps      | 847872    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.71e+14  |\n",
            "|    n_updates            | 4130      |\n",
            "|    policy_gradient_loss | -3.88e-08 |\n",
            "|    reward               | 1471642.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.35e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 425       |\n",
            "|    iterations           | 415       |\n",
            "|    time_elapsed         | 1996      |\n",
            "|    total_timesteps      | 849920    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.27e+14  |\n",
            "|    n_updates            | 4140      |\n",
            "|    policy_gradient_loss | -2.61e-07 |\n",
            "|    reward               | 1982896.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.79e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2083024.4482017288\n",
            "Sharpe:  0.63141842181936\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 425       |\n",
            "|    iterations           | 416       |\n",
            "|    time_elapsed         | 2001      |\n",
            "|    total_timesteps      | 851968    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.6e+14   |\n",
            "|    n_updates            | 4150      |\n",
            "|    policy_gradient_loss | -2.02e-07 |\n",
            "|    reward               | 1957125.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.12e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2358289.6699208072\n",
            "Sharpe:  0.7337560579259255\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 425       |\n",
            "|    iterations           | 417       |\n",
            "|    time_elapsed         | 2007      |\n",
            "|    total_timesteps      | 854016    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.45e+14  |\n",
            "|    n_updates            | 4160      |\n",
            "|    policy_gradient_loss | -2.18e-07 |\n",
            "|    reward               | 1082509.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.78e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 425       |\n",
            "|    iterations           | 418       |\n",
            "|    time_elapsed         | 2012      |\n",
            "|    total_timesteps      | 856064    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.33e+14  |\n",
            "|    n_updates            | 4170      |\n",
            "|    policy_gradient_loss | -1.69e-07 |\n",
            "|    reward               | 1902323.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.12e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2171027.628812852\n",
            "Sharpe:  0.6637940175321316\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 425       |\n",
            "|    iterations           | 419       |\n",
            "|    time_elapsed         | 2018      |\n",
            "|    total_timesteps      | 858112    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.35e+14  |\n",
            "|    n_updates            | 4180      |\n",
            "|    policy_gradient_loss | -2.24e-07 |\n",
            "|    reward               | 1369586.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.93e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 424       |\n",
            "|    iterations           | 420       |\n",
            "|    time_elapsed         | 2023      |\n",
            "|    total_timesteps      | 860160    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.94e+14  |\n",
            "|    n_updates            | 4190      |\n",
            "|    policy_gradient_loss | -3.36e-07 |\n",
            "|    reward               | 1892922.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8e+14     |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2275078.9762142706\n",
            "Sharpe:  0.7049764371824164\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 424       |\n",
            "|    iterations           | 421       |\n",
            "|    time_elapsed         | 2029      |\n",
            "|    total_timesteps      | 862208    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.57e+14  |\n",
            "|    n_updates            | 4200      |\n",
            "|    policy_gradient_loss | -1.78e-07 |\n",
            "|    reward               | 1658337.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.92e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 424       |\n",
            "|    iterations           | 422       |\n",
            "|    time_elapsed         | 2035      |\n",
            "|    total_timesteps      | 864256    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.57e+14  |\n",
            "|    n_updates            | 4210      |\n",
            "|    policy_gradient_loss | -2.56e-07 |\n",
            "|    reward               | 2100957.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.31e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2244420.511086007\n",
            "Sharpe:  0.7002500850277656\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 424       |\n",
            "|    iterations           | 423       |\n",
            "|    time_elapsed         | 2040      |\n",
            "|    total_timesteps      | 866304    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.68e+14  |\n",
            "|    n_updates            | 4220      |\n",
            "|    policy_gradient_loss | -8.48e-08 |\n",
            "|    reward               | 1865296.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.14e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2103884.8378392556\n",
            "Sharpe:  0.6527840519955488\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 424       |\n",
            "|    iterations           | 424       |\n",
            "|    time_elapsed         | 2046      |\n",
            "|    total_timesteps      | 868352    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3e+14     |\n",
            "|    n_updates            | 4230      |\n",
            "|    policy_gradient_loss | -7.96e-08 |\n",
            "|    reward               | 1156345.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.21e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 424       |\n",
            "|    iterations           | 425       |\n",
            "|    time_elapsed         | 2051      |\n",
            "|    total_timesteps      | 870400    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.19e+14  |\n",
            "|    n_updates            | 4240      |\n",
            "|    policy_gradient_loss | -2.04e-07 |\n",
            "|    reward               | 2112604.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.63e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2402680.726907724\n",
            "Sharpe:  0.7361115683325045\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 424       |\n",
            "|    iterations           | 426       |\n",
            "|    time_elapsed         | 2057      |\n",
            "|    total_timesteps      | 872448    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.12e+14  |\n",
            "|    n_updates            | 4250      |\n",
            "|    policy_gradient_loss | -2.83e-07 |\n",
            "|    reward               | 1117842.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.1e+14   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 423       |\n",
            "|    iterations           | 427       |\n",
            "|    time_elapsed         | 2062      |\n",
            "|    total_timesteps      | 874496    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -2.38e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.39e+14  |\n",
            "|    n_updates            | 4260      |\n",
            "|    policy_gradient_loss | -1.7e-07  |\n",
            "|    reward               | 1649318.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.02e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1830651.4920783723\n",
            "Sharpe:  0.5417669566604422\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 423       |\n",
            "|    iterations           | 428       |\n",
            "|    time_elapsed         | 2068      |\n",
            "|    total_timesteps      | 876544    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.34e+14  |\n",
            "|    n_updates            | 4270      |\n",
            "|    policy_gradient_loss | -1.55e-07 |\n",
            "|    reward               | 1929368.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.62e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 423       |\n",
            "|    iterations           | 429       |\n",
            "|    time_elapsed         | 2073      |\n",
            "|    total_timesteps      | 878592    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.01e+14  |\n",
            "|    n_updates            | 4280      |\n",
            "|    policy_gradient_loss | -8.36e-08 |\n",
            "|    reward               | 2245997.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.32e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2304789.5625292687\n",
            "Sharpe:  0.7136485683900827\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 423       |\n",
            "|    iterations           | 430       |\n",
            "|    time_elapsed         | 2079      |\n",
            "|    total_timesteps      | 880640    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.61e+14  |\n",
            "|    n_updates            | 4290      |\n",
            "|    policy_gradient_loss | -2.08e-07 |\n",
            "|    reward               | 1883305.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.12e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2402043.2907635663\n",
            "Sharpe:  0.7509543854920099\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 423       |\n",
            "|    iterations           | 431       |\n",
            "|    time_elapsed         | 2085      |\n",
            "|    total_timesteps      | 882688    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.64e+14  |\n",
            "|    n_updates            | 4300      |\n",
            "|    policy_gradient_loss | -1.09e-07 |\n",
            "|    reward               | 1328642.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.81e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 423       |\n",
            "|    iterations           | 432       |\n",
            "|    time_elapsed         | 2091      |\n",
            "|    total_timesteps      | 884736    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.09e+14  |\n",
            "|    n_updates            | 4310      |\n",
            "|    policy_gradient_loss | -2.72e-07 |\n",
            "|    reward               | 1594320.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.01e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1963147.4657491436\n",
            "Sharpe:  0.5974847417582857\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 422       |\n",
            "|    iterations           | 433       |\n",
            "|    time_elapsed         | 2097      |\n",
            "|    total_timesteps      | 886784    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.82e+14  |\n",
            "|    n_updates            | 4320      |\n",
            "|    policy_gradient_loss | -3.04e-07 |\n",
            "|    reward               | 1338919.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.73e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 422       |\n",
            "|    iterations           | 434       |\n",
            "|    time_elapsed         | 2102      |\n",
            "|    total_timesteps      | 888832    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.29e+14  |\n",
            "|    n_updates            | 4330      |\n",
            "|    policy_gradient_loss | -4.05e-08 |\n",
            "|    reward               | 1786966.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.34e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1927872.294799277\n",
            "Sharpe:  0.5772580088470984\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 422       |\n",
            "|    iterations           | 435       |\n",
            "|    time_elapsed         | 2108      |\n",
            "|    total_timesteps      | 890880    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.84e+14  |\n",
            "|    n_updates            | 4340      |\n",
            "|    policy_gradient_loss | -1.22e-07 |\n",
            "|    reward               | 1817897.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.67e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1989516.6730217617\n",
            "Sharpe:  0.6028125613131365\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 422       |\n",
            "|    iterations           | 436       |\n",
            "|    time_elapsed         | 2114      |\n",
            "|    total_timesteps      | 892928    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.03e+14  |\n",
            "|    n_updates            | 4350      |\n",
            "|    policy_gradient_loss | -1.66e-07 |\n",
            "|    reward               | 1084202.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.05e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 422       |\n",
            "|    iterations           | 437       |\n",
            "|    time_elapsed         | 2119      |\n",
            "|    total_timesteps      | 894976    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.48e+14  |\n",
            "|    n_updates            | 4360      |\n",
            "|    policy_gradient_loss | -3.57e-08 |\n",
            "|    reward               | 1910413.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.92e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2120526.882233982\n",
            "Sharpe:  0.6591774605892301\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 422       |\n",
            "|    iterations           | 438       |\n",
            "|    time_elapsed         | 2125      |\n",
            "|    total_timesteps      | 897024    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.15e+14  |\n",
            "|    n_updates            | 4370      |\n",
            "|    policy_gradient_loss | -1.8e-07  |\n",
            "|    reward               | 1343703.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.43e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 421       |\n",
            "|    iterations           | 439       |\n",
            "|    time_elapsed         | 2131      |\n",
            "|    total_timesteps      | 899072    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.26e+14  |\n",
            "|    n_updates            | 4380      |\n",
            "|    policy_gradient_loss | -1.96e-07 |\n",
            "|    reward               | 1808753.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.14e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2013591.734928123\n",
            "Sharpe:  0.6191867222968612\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 421       |\n",
            "|    iterations           | 440       |\n",
            "|    time_elapsed         | 2136      |\n",
            "|    total_timesteps      | 901120    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.77e+14  |\n",
            "|    n_updates            | 4390      |\n",
            "|    policy_gradient_loss | -1.52e-07 |\n",
            "|    reward               | 1432592.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.71e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 421       |\n",
            "|    iterations           | 441       |\n",
            "|    time_elapsed         | 2142      |\n",
            "|    total_timesteps      | 903168    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.35e+14  |\n",
            "|    n_updates            | 4400      |\n",
            "|    policy_gradient_loss | -2.35e-07 |\n",
            "|    reward               | 1825890.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.47e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2011105.1677339661\n",
            "Sharpe:  0.5984277211217391\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 421       |\n",
            "|    iterations           | 442       |\n",
            "|    time_elapsed         | 2147      |\n",
            "|    total_timesteps      | 905216    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.31e+14  |\n",
            "|    n_updates            | 4410      |\n",
            "|    policy_gradient_loss | -1.61e-07 |\n",
            "|    reward               | 2075486.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.5e+14   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2336210.5794573184\n",
            "Sharpe:  0.7155752743069257\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 421       |\n",
            "|    iterations           | 443       |\n",
            "|    time_elapsed         | 2153      |\n",
            "|    total_timesteps      | 907264    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.89e+14  |\n",
            "|    n_updates            | 4420      |\n",
            "|    policy_gradient_loss | -8.74e-08 |\n",
            "|    reward               | 1087325.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.47e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 421       |\n",
            "|    iterations           | 444       |\n",
            "|    time_elapsed         | 2158      |\n",
            "|    total_timesteps      | 909312    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.36e+14  |\n",
            "|    n_updates            | 4430      |\n",
            "|    policy_gradient_loss | -2.02e-07 |\n",
            "|    reward               | 1810070.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.1e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2033443.0544405808\n",
            "Sharpe:  0.6110088423610859\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 421       |\n",
            "|    iterations           | 445       |\n",
            "|    time_elapsed         | 2164      |\n",
            "|    total_timesteps      | 911360    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.46e+14  |\n",
            "|    n_updates            | 4440      |\n",
            "|    policy_gradient_loss | -1.3e-07  |\n",
            "|    reward               | 1097546.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.64e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 446       |\n",
            "|    time_elapsed         | 2169      |\n",
            "|    total_timesteps      | 913408    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.81e+14  |\n",
            "|    n_updates            | 4450      |\n",
            "|    policy_gradient_loss | -1.77e-07 |\n",
            "|    reward               | 1807687.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.26e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2008687.0471676209\n",
            "Sharpe:  0.5991129378918122\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 447       |\n",
            "|    time_elapsed         | 2175      |\n",
            "|    total_timesteps      | 915456    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.6e+14   |\n",
            "|    n_updates            | 4460      |\n",
            "|    policy_gradient_loss | -1.51e-07 |\n",
            "|    reward               | 1877735.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.17e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 448       |\n",
            "|    time_elapsed         | 2181      |\n",
            "|    total_timesteps      | 917504    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.31e+14  |\n",
            "|    n_updates            | 4470      |\n",
            "|    policy_gradient_loss | -3.02e-07 |\n",
            "|    reward               | 2214871.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.62e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2316211.617493152\n",
            "Sharpe:  0.6973339839200579\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 449       |\n",
            "|    time_elapsed         | 2186      |\n",
            "|    total_timesteps      | 919552    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.06e+14  |\n",
            "|    n_updates            | 4480      |\n",
            "|    policy_gradient_loss | -2.43e-08 |\n",
            "|    reward               | 1756953.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.21e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2147007.671754277\n",
            "Sharpe:  0.6551757265654969\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 450       |\n",
            "|    time_elapsed         | 2192      |\n",
            "|    total_timesteps      | 921600    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.15e+14  |\n",
            "|    n_updates            | 4490      |\n",
            "|    policy_gradient_loss | -3.77e-07 |\n",
            "|    reward               | 1170537.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.93e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 451       |\n",
            "|    time_elapsed         | 2197      |\n",
            "|    total_timesteps      | 923648    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.21e+14  |\n",
            "|    n_updates            | 4500      |\n",
            "|    policy_gradient_loss | -1.44e-07 |\n",
            "|    reward               | 1632427.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.54e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1981652.9330136194\n",
            "Sharpe:  0.603028425862551\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 452       |\n",
            "|    time_elapsed         | 2203      |\n",
            "|    total_timesteps      | 925696    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.42e+14  |\n",
            "|    n_updates            | 4510      |\n",
            "|    policy_gradient_loss | -1.82e-07 |\n",
            "|    reward               | 1573096.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.01e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 453       |\n",
            "|    time_elapsed         | 2209      |\n",
            "|    total_timesteps      | 927744    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.24e+14  |\n",
            "|    n_updates            | 4520      |\n",
            "|    policy_gradient_loss | -1.24e-07 |\n",
            "|    reward               | 2024810.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.75e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2293017.0460272715\n",
            "Sharpe:  0.7248470374368776\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 454       |\n",
            "|    time_elapsed         | 2215      |\n",
            "|    total_timesteps      | 929792    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -3.58e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.25e+14  |\n",
            "|    n_updates            | 4530      |\n",
            "|    policy_gradient_loss | -1.63e-07 |\n",
            "|    reward               | 1887450.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.03e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2286325.0487479432\n",
            "Sharpe:  0.7141129647189192\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 455       |\n",
            "|    time_elapsed         | 2220      |\n",
            "|    total_timesteps      | 931840    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.72e+14  |\n",
            "|    n_updates            | 4540      |\n",
            "|    policy_gradient_loss | -2.64e-07 |\n",
            "|    reward               | 1037320.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.24e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 456       |\n",
            "|    time_elapsed         | 2226      |\n",
            "|    total_timesteps      | 933888    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.48e+14  |\n",
            "|    n_updates            | 4550      |\n",
            "|    policy_gradient_loss | -1.26e-07 |\n",
            "|    reward               | 1776734.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.08e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1951538.072112971\n",
            "Sharpe:  0.600319789867768\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 457       |\n",
            "|    time_elapsed         | 2231      |\n",
            "|    total_timesteps      | 935936    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.17e+14  |\n",
            "|    n_updates            | 4560      |\n",
            "|    policy_gradient_loss | -1.48e-07 |\n",
            "|    reward               | 1368469.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.15e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 458       |\n",
            "|    time_elapsed         | 2237      |\n",
            "|    total_timesteps      | 937984    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.49e+14  |\n",
            "|    n_updates            | 4570      |\n",
            "|    policy_gradient_loss | -1.56e-07 |\n",
            "|    reward               | 2091481.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.23e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2495380.0802638913\n",
            "Sharpe:  0.7812806087174916\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 459       |\n",
            "|    time_elapsed         | 2243      |\n",
            "|    total_timesteps      | 940032    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 2.98e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.1e+14   |\n",
            "|    n_updates            | 4580      |\n",
            "|    policy_gradient_loss | -1.5e-07  |\n",
            "|    reward               | 1627557.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.02e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 460       |\n",
            "|    time_elapsed         | 2248      |\n",
            "|    total_timesteps      | 942080    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.25e+14  |\n",
            "|    n_updates            | 4590      |\n",
            "|    policy_gradient_loss | -3.71e-07 |\n",
            "|    reward               | 2038529.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.97e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2161375.8168695252\n",
            "Sharpe:  0.6786491083738977\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 461       |\n",
            "|    time_elapsed         | 2254      |\n",
            "|    total_timesteps      | 944128    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.4e+14   |\n",
            "|    n_updates            | 4600      |\n",
            "|    policy_gradient_loss | -1.7e-07  |\n",
            "|    reward               | 1779800.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.07e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1931869.085021241\n",
            "Sharpe:  0.575705963278988\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 418        |\n",
            "|    iterations           | 462        |\n",
            "|    time_elapsed         | 2260       |\n",
            "|    total_timesteps      | 946176     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.0        |\n",
            "|    clip_fraction        | 0          |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -9.93      |\n",
            "|    explained_variance   | -1.19e-07  |\n",
            "|    learning_rate        | 0.0001     |\n",
            "|    loss                 | 3.2e+14    |\n",
            "|    n_updates            | 4610       |\n",
            "|    policy_gradient_loss | -1.74e-07  |\n",
            "|    reward               | 1038281.25 |\n",
            "|    std                  | 1          |\n",
            "|    value_loss           | 6.27e+14   |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 463       |\n",
            "|    time_elapsed         | 2266      |\n",
            "|    total_timesteps      | 948224    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.13e+14  |\n",
            "|    n_updates            | 4620      |\n",
            "|    policy_gradient_loss | -8.6e-08  |\n",
            "|    reward               | 1971423.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8e+14     |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2124463.451205257\n",
            "Sharpe:  0.649381102476848\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 464       |\n",
            "|    time_elapsed         | 2271      |\n",
            "|    total_timesteps      | 950272    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.5e+14   |\n",
            "|    n_updates            | 4630      |\n",
            "|    policy_gradient_loss | -9.67e-08 |\n",
            "|    reward               | 1116069.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.37e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 465       |\n",
            "|    time_elapsed         | 2277      |\n",
            "|    total_timesteps      | 952320    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4e+14     |\n",
            "|    n_updates            | 4640      |\n",
            "|    policy_gradient_loss | -1.46e-07 |\n",
            "|    reward               | 1704266.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.96e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2055219.8092780137\n",
            "Sharpe:  0.6089537418918485\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 466       |\n",
            "|    time_elapsed         | 2283      |\n",
            "|    total_timesteps      | 954368    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.64e+14  |\n",
            "|    n_updates            | 4650      |\n",
            "|    policy_gradient_loss | -1.45e-07 |\n",
            "|    reward               | 1662078.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.37e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 467       |\n",
            "|    time_elapsed         | 2288      |\n",
            "|    total_timesteps      | 956416    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.97e+14  |\n",
            "|    n_updates            | 4660      |\n",
            "|    policy_gradient_loss | -1.79e-07 |\n",
            "|    reward               | 1904930.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.23e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2048612.9930908382\n",
            "Sharpe:  0.6290660335443646\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 468       |\n",
            "|    time_elapsed         | 2294      |\n",
            "|    total_timesteps      | 958464    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.51e+14  |\n",
            "|    n_updates            | 4670      |\n",
            "|    policy_gradient_loss | -1.08e-07 |\n",
            "|    reward               | 1924651.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.96e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2200114.2844658014\n",
            "Sharpe:  0.6821293933515057\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 469       |\n",
            "|    time_elapsed         | 2299      |\n",
            "|    total_timesteps      | 960512    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.44e+14  |\n",
            "|    n_updates            | 4680      |\n",
            "|    policy_gradient_loss | -2.68e-07 |\n",
            "|    reward               | 1257862.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.44e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 470       |\n",
            "|    time_elapsed         | 2305      |\n",
            "|    total_timesteps      | 962560    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.77e+14  |\n",
            "|    n_updates            | 4690      |\n",
            "|    policy_gradient_loss | -1.41e-07 |\n",
            "|    reward               | 1795919.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.36e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2061264.2791107304\n",
            "Sharpe:  0.6240567486204245\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 471       |\n",
            "|    time_elapsed         | 2311      |\n",
            "|    total_timesteps      | 964608    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.81e+14  |\n",
            "|    n_updates            | 4700      |\n",
            "|    policy_gradient_loss | -1.56e-07 |\n",
            "|    reward               | 1270990.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.56e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 472       |\n",
            "|    time_elapsed         | 2316      |\n",
            "|    total_timesteps      | 966656    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.58e+14  |\n",
            "|    n_updates            | 4710      |\n",
            "|    policy_gradient_loss | -8.01e-08 |\n",
            "|    reward               | 2027160.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.99e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2209047.4316955707\n",
            "Sharpe:  0.7005195499498871\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 473       |\n",
            "|    time_elapsed         | 2322      |\n",
            "|    total_timesteps      | 968704    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.49e+14  |\n",
            "|    n_updates            | 4720      |\n",
            "|    policy_gradient_loss | -2.19e-07 |\n",
            "|    reward               | 1677200.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.92e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 474       |\n",
            "|    time_elapsed         | 2327      |\n",
            "|    total_timesteps      | 970752    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -3.58e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.38e+14  |\n",
            "|    n_updates            | 4730      |\n",
            "|    policy_gradient_loss | -1.74e-07 |\n",
            "|    reward               | 2085753.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.97e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2131274.3622508375\n",
            "Sharpe:  0.6637549893804926\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 475       |\n",
            "|    time_elapsed         | 2332      |\n",
            "|    total_timesteps      | 972800    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.78e+14  |\n",
            "|    n_updates            | 4740      |\n",
            "|    policy_gradient_loss | -5.98e-08 |\n",
            "|    reward               | 1689320.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.68e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1885833.7322211051\n",
            "Sharpe:  0.5462508007302734\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 476       |\n",
            "|    time_elapsed         | 2337      |\n",
            "|    total_timesteps      | 974848    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.73e+14  |\n",
            "|    n_updates            | 4750      |\n",
            "|    policy_gradient_loss | -2e-07    |\n",
            "|    reward               | 1353632.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.46e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 477       |\n",
            "|    time_elapsed         | 2341      |\n",
            "|    total_timesteps      | 976896    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.61e+14  |\n",
            "|    n_updates            | 4760      |\n",
            "|    policy_gradient_loss | -7.56e-08 |\n",
            "|    reward               | 1513721.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.01e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1743939.3200526687\n",
            "Sharpe:  0.48797733920949504\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 478       |\n",
            "|    time_elapsed         | 2346      |\n",
            "|    total_timesteps      | 978944    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.08e+14  |\n",
            "|    n_updates            | 4770      |\n",
            "|    policy_gradient_loss | -2.61e-07 |\n",
            "|    reward               | 1419669.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.28e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 479       |\n",
            "|    time_elapsed         | 2351      |\n",
            "|    total_timesteps      | 980992    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.86e+14  |\n",
            "|    n_updates            | 4780      |\n",
            "|    policy_gradient_loss | -4.09e-07 |\n",
            "|    reward               | 1968794.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.64e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2140966.14156125\n",
            "Sharpe:  0.654916392017773\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 480       |\n",
            "|    time_elapsed         | 2356      |\n",
            "|    total_timesteps      | 983040    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.44e+14  |\n",
            "|    n_updates            | 4790      |\n",
            "|    policy_gradient_loss | -1.25e-07 |\n",
            "|    reward               | 1723009.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.73e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2133303.8142835293\n",
            "Sharpe:  0.6458477127387234\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 481       |\n",
            "|    time_elapsed         | 2360      |\n",
            "|    total_timesteps      | 985088    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.33e+14  |\n",
            "|    n_updates            | 4800      |\n",
            "|    policy_gradient_loss | -1.52e-07 |\n",
            "|    reward               | 999916.1  |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.38e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 482       |\n",
            "|    time_elapsed         | 2365      |\n",
            "|    total_timesteps      | 987136    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.86e+14  |\n",
            "|    n_updates            | 4810      |\n",
            "|    policy_gradient_loss | -1.61e-07 |\n",
            "|    reward               | 1611105.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.55e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1709333.747975543\n",
            "Sharpe:  0.49057712498942607\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 483       |\n",
            "|    time_elapsed         | 2370      |\n",
            "|    total_timesteps      | 989184    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.63e+14  |\n",
            "|    n_updates            | 4820      |\n",
            "|    policy_gradient_loss | -7.17e-07 |\n",
            "|    reward               | 1235352.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.01e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 484       |\n",
            "|    time_elapsed         | 2374      |\n",
            "|    total_timesteps      | 991232    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.81e+14  |\n",
            "|    n_updates            | 4830      |\n",
            "|    policy_gradient_loss | -1.51e-07 |\n",
            "|    reward               | 1818561.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.67e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2173732.0837526005\n",
            "Sharpe:  0.685833140870713\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 485       |\n",
            "|    time_elapsed         | 2379      |\n",
            "|    total_timesteps      | 993280    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.9e+14   |\n",
            "|    n_updates            | 4840      |\n",
            "|    policy_gradient_loss | -2.18e-07 |\n",
            "|    reward               | 1641393.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.78e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 486       |\n",
            "|    time_elapsed         | 2384      |\n",
            "|    total_timesteps      | 995328    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.99e+14  |\n",
            "|    n_updates            | 4850      |\n",
            "|    policy_gradient_loss | -2.88e-08 |\n",
            "|    reward               | 1884082.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.89e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2106613.7763737906\n",
            "Sharpe:  0.6464999949258925\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 487       |\n",
            "|    time_elapsed         | 2389      |\n",
            "|    total_timesteps      | 997376    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.64e+14  |\n",
            "|    n_updates            | 4860      |\n",
            "|    policy_gradient_loss | -5.79e-09 |\n",
            "|    reward               | 1711295.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.23e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1830873.1821127753\n",
            "Sharpe:  0.532462155907335\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 488       |\n",
            "|    time_elapsed         | 2393      |\n",
            "|    total_timesteps      | 999424    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.96e+14  |\n",
            "|    n_updates            | 4870      |\n",
            "|    policy_gradient_loss | -9.69e-08 |\n",
            "|    reward               | 1149372.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.86e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 489       |\n",
            "|    time_elapsed         | 2398      |\n",
            "|    total_timesteps      | 1001472   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.51e+14  |\n",
            "|    n_updates            | 4880      |\n",
            "|    policy_gradient_loss | -3.88e-07 |\n",
            "|    reward               | 1859095.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.11e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2058465.3171143865\n",
            "Sharpe:  0.6327076160558416\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 490       |\n",
            "|    time_elapsed         | 2403      |\n",
            "|    total_timesteps      | 1003520   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.04e+14  |\n",
            "|    n_updates            | 4890      |\n",
            "|    policy_gradient_loss | -2.34e-07 |\n",
            "|    reward               | 1169636.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.86e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 491       |\n",
            "|    time_elapsed         | 2407      |\n",
            "|    total_timesteps      | 1005568   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.88e+14  |\n",
            "|    n_updates            | 4900      |\n",
            "|    policy_gradient_loss | -2.28e-07 |\n",
            "|    reward               | 1993153.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.35e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2204909.444972971\n",
            "Sharpe:  0.6822270952532654\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 492       |\n",
            "|    time_elapsed         | 2412      |\n",
            "|    total_timesteps      | 1007616   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.17e+14  |\n",
            "|    n_updates            | 4910      |\n",
            "|    policy_gradient_loss | -1.45e-07 |\n",
            "|    reward               | 1477764.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.6e+14   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 493       |\n",
            "|    time_elapsed         | 2417      |\n",
            "|    total_timesteps      | 1009664   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.44e+14  |\n",
            "|    n_updates            | 4920      |\n",
            "|    policy_gradient_loss | -9.73e-08 |\n",
            "|    reward               | 1693082.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.46e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1773471.4972300504\n",
            "Sharpe:  0.5051008059721614\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 494       |\n",
            "|    time_elapsed         | 2422      |\n",
            "|    total_timesteps      | 1011712   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.39e+14  |\n",
            "|    n_updates            | 4930      |\n",
            "|    policy_gradient_loss | -2.22e-07 |\n",
            "|    reward               | 1862345.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.74e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2128529.741155368\n",
            "Sharpe:  0.6565307610019676\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 495       |\n",
            "|    time_elapsed         | 2426      |\n",
            "|    total_timesteps      | 1013760   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.25e+14  |\n",
            "|    n_updates            | 4940      |\n",
            "|    policy_gradient_loss | -1.6e-07  |\n",
            "|    reward               | 1207900.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.23e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 496       |\n",
            "|    time_elapsed         | 2431      |\n",
            "|    total_timesteps      | 1015808   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.42e+14  |\n",
            "|    n_updates            | 4950      |\n",
            "|    policy_gradient_loss | -9.49e-08 |\n",
            "|    reward               | 1710068.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.9e+14   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2102901.261036884\n",
            "Sharpe:  0.64947564490723\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 497       |\n",
            "|    time_elapsed         | 2436      |\n",
            "|    total_timesteps      | 1017856   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.39e+14  |\n",
            "|    n_updates            | 4960      |\n",
            "|    policy_gradient_loss | -1.59e-07 |\n",
            "|    reward               | 1514805.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.93e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 498       |\n",
            "|    time_elapsed         | 2440      |\n",
            "|    total_timesteps      | 1019904   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.51e+14  |\n",
            "|    n_updates            | 4970      |\n",
            "|    policy_gradient_loss | -1.25e-07 |\n",
            "|    reward               | 1882737.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7e+14     |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2095515.6076174944\n",
            "Sharpe:  0.6563474483326373\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 499       |\n",
            "|    time_elapsed         | 2446      |\n",
            "|    total_timesteps      | 1021952   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.47e+14  |\n",
            "|    n_updates            | 4980      |\n",
            "|    policy_gradient_loss | -4.13e-08 |\n",
            "|    reward               | 1773274.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.92e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1942907.7632889808\n",
            "Sharpe:  0.5685871305536485\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 500       |\n",
            "|    time_elapsed         | 2450      |\n",
            "|    total_timesteps      | 1024000   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.11e+14  |\n",
            "|    n_updates            | 4990      |\n",
            "|    policy_gradient_loss | -3.2e-07  |\n",
            "|    reward               | 1052418.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.18e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 501       |\n",
            "|    time_elapsed         | 2455      |\n",
            "|    total_timesteps      | 1026048   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.35e+14  |\n",
            "|    n_updates            | 5000      |\n",
            "|    policy_gradient_loss | -3.02e-08 |\n",
            "|    reward               | 1901405.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.68e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2024782.158304955\n",
            "Sharpe:  0.6143701454892359\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 502       |\n",
            "|    time_elapsed         | 2460      |\n",
            "|    total_timesteps      | 1028096   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.29e+14  |\n",
            "|    n_updates            | 5010      |\n",
            "|    policy_gradient_loss | -2.5e-07  |\n",
            "|    reward               | 1337338.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.51e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 503       |\n",
            "|    time_elapsed         | 2464      |\n",
            "|    total_timesteps      | 1030144   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.03e+14  |\n",
            "|    n_updates            | 5020      |\n",
            "|    policy_gradient_loss | -2.3e-07  |\n",
            "|    reward               | 1698054.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.59e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1922516.9759253457\n",
            "Sharpe:  0.5717195092678676\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 504       |\n",
            "|    time_elapsed         | 2469      |\n",
            "|    total_timesteps      | 1032192   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.41e+14  |\n",
            "|    n_updates            | 5030      |\n",
            "|    policy_gradient_loss | -1.65e-07 |\n",
            "|    reward               | 1447547.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.8e+14   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 417       |\n",
            "|    iterations           | 505       |\n",
            "|    time_elapsed         | 2474      |\n",
            "|    total_timesteps      | 1034240   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.04e+14  |\n",
            "|    n_updates            | 5040      |\n",
            "|    policy_gradient_loss | -1.3e-07  |\n",
            "|    reward               | 1777497.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.06e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1914220.8472524942\n",
            "Sharpe:  0.5681106135916117\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 506       |\n",
            "|    time_elapsed         | 2479      |\n",
            "|    total_timesteps      | 1036288   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.25e+14  |\n",
            "|    n_updates            | 5050      |\n",
            "|    policy_gradient_loss | -4.99e-08 |\n",
            "|    reward               | 1855905.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.45e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2035759.9450847548\n",
            "Sharpe:  0.6122777914765939\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 507       |\n",
            "|    time_elapsed         | 2483      |\n",
            "|    total_timesteps      | 1038336   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.23e+14  |\n",
            "|    n_updates            | 5060      |\n",
            "|    policy_gradient_loss | -4.4e-07  |\n",
            "|    reward               | 1069498.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.13e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 508       |\n",
            "|    time_elapsed         | 2488      |\n",
            "|    total_timesteps      | 1040384   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.04e+14  |\n",
            "|    n_updates            | 5070      |\n",
            "|    policy_gradient_loss | -1.07e-07 |\n",
            "|    reward               | 1770408.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.37e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2043873.7181944516\n",
            "Sharpe:  0.6182450840031498\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 509       |\n",
            "|    time_elapsed         | 2493      |\n",
            "|    total_timesteps      | 1042432   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.43e+14  |\n",
            "|    n_updates            | 5080      |\n",
            "|    policy_gradient_loss | -3.95e-07 |\n",
            "|    reward               | 1277561.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.51e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 510       |\n",
            "|    time_elapsed         | 2497      |\n",
            "|    total_timesteps      | 1044480   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.63e+14  |\n",
            "|    n_updates            | 5090      |\n",
            "|    policy_gradient_loss | -1.57e-07 |\n",
            "|    reward               | 1896146.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.48e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2183374.5153450863\n",
            "Sharpe:  0.6809260131723407\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 511       |\n",
            "|    time_elapsed         | 2502      |\n",
            "|    total_timesteps      | 1046528   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.77e+14  |\n",
            "|    n_updates            | 5100      |\n",
            "|    policy_gradient_loss | -3.62e-07 |\n",
            "|    reward               | 1678690.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.35e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 512       |\n",
            "|    time_elapsed         | 2507      |\n",
            "|    total_timesteps      | 1048576   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -2.38e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.14e+14  |\n",
            "|    n_updates            | 5110      |\n",
            "|    policy_gradient_loss | -6.19e-08 |\n",
            "|    reward               | 2047736.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.73e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2223731.5656866096\n",
            "Sharpe:  0.6841266451895631\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 513       |\n",
            "|    time_elapsed         | 2512      |\n",
            "|    total_timesteps      | 1050624   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.82e+14  |\n",
            "|    n_updates            | 5120      |\n",
            "|    policy_gradient_loss | -1.53e-07 |\n",
            "|    reward               | 1911478.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.74e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2169417.05194202\n",
            "Sharpe:  0.6701117566315294\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 514       |\n",
            "|    time_elapsed         | 2516      |\n",
            "|    total_timesteps      | 1052672   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.61e+14  |\n",
            "|    n_updates            | 5130      |\n",
            "|    policy_gradient_loss | -1.57e-07 |\n",
            "|    reward               | 1199999.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.67e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 515       |\n",
            "|    time_elapsed         | 2521      |\n",
            "|    total_timesteps      | 1054720   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.46e+14  |\n",
            "|    n_updates            | 5140      |\n",
            "|    policy_gradient_loss | -8.81e-08 |\n",
            "|    reward               | 1808075.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.18e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2188439.2839306667\n",
            "Sharpe:  0.6756923036743109\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 516       |\n",
            "|    time_elapsed         | 2526      |\n",
            "|    total_timesteps      | 1056768   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.41e+14  |\n",
            "|    n_updates            | 5150      |\n",
            "|    policy_gradient_loss | -2e-07    |\n",
            "|    reward               | 1349386.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.97e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 517       |\n",
            "|    time_elapsed         | 2531      |\n",
            "|    total_timesteps      | 1058816   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.03e+14  |\n",
            "|    n_updates            | 5160      |\n",
            "|    policy_gradient_loss | -1.34e-07 |\n",
            "|    reward               | 1830401.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.99e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1954907.6370675636\n",
            "Sharpe:  0.5833261173660556\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 518       |\n",
            "|    time_elapsed         | 2536      |\n",
            "|    total_timesteps      | 1060864   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.24e+14  |\n",
            "|    n_updates            | 5170      |\n",
            "|    policy_gradient_loss | -2.02e-07 |\n",
            "|    reward               | 1727698.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.43e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2030439.8150183444\n",
            "Sharpe:  0.613238431239259\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 519       |\n",
            "|    time_elapsed         | 2541      |\n",
            "|    total_timesteps      | 1062912   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.1e+14   |\n",
            "|    n_updates            | 5180      |\n",
            "|    policy_gradient_loss | -3.04e-07 |\n",
            "|    reward               | 1001811.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.45e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 520       |\n",
            "|    time_elapsed         | 2545      |\n",
            "|    total_timesteps      | 1064960   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.64e+14  |\n",
            "|    n_updates            | 5190      |\n",
            "|    policy_gradient_loss | -3.73e-08 |\n",
            "|    reward               | 1622082.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.18e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1845591.8946439193\n",
            "Sharpe:  0.544164042386788\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 521       |\n",
            "|    time_elapsed         | 2550      |\n",
            "|    total_timesteps      | 1067008   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.8e+14   |\n",
            "|    n_updates            | 5200      |\n",
            "|    policy_gradient_loss | -1.99e-07 |\n",
            "|    reward               | 1387227.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.39e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 522       |\n",
            "|    time_elapsed         | 2555      |\n",
            "|    total_timesteps      | 1069056   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.2e+14   |\n",
            "|    n_updates            | 5210      |\n",
            "|    policy_gradient_loss | -2.61e-07 |\n",
            "|    reward               | 1745818.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.52e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2035207.4428671452\n",
            "Sharpe:  0.625635488012022\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 523       |\n",
            "|    time_elapsed         | 2560      |\n",
            "|    total_timesteps      | 1071104   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.69e+14  |\n",
            "|    n_updates            | 5220      |\n",
            "|    policy_gradient_loss | -1.42e-07 |\n",
            "|    reward               | 1426665.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.5e+14   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 524       |\n",
            "|    time_elapsed         | 2565      |\n",
            "|    total_timesteps      | 1073152   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.08e+14  |\n",
            "|    n_updates            | 5230      |\n",
            "|    policy_gradient_loss | -1.68e-07 |\n",
            "|    reward               | 1877642.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.53e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2075424.6368183936\n",
            "Sharpe:  0.624861713337055\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 525       |\n",
            "|    time_elapsed         | 2570      |\n",
            "|    total_timesteps      | 1075200   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.21e+14  |\n",
            "|    n_updates            | 5240      |\n",
            "|    policy_gradient_loss | -3.64e-07 |\n",
            "|    reward               | 1608214.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.53e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1926236.1792638835\n",
            "Sharpe:  0.5744373519467624\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 526       |\n",
            "|    time_elapsed         | 2574      |\n",
            "|    total_timesteps      | 1077248   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.02e+14  |\n",
            "|    n_updates            | 5250      |\n",
            "|    policy_gradient_loss | -1.26e-07 |\n",
            "|    reward               | 1067924.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.85e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 527       |\n",
            "|    time_elapsed         | 2579      |\n",
            "|    total_timesteps      | 1079296   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.61e+14  |\n",
            "|    n_updates            | 5260      |\n",
            "|    policy_gradient_loss | -2.56e-07 |\n",
            "|    reward               | 1804039.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.5e+14   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2092615.4594278329\n",
            "Sharpe:  0.6296472340830406\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 528       |\n",
            "|    time_elapsed         | 2584      |\n",
            "|    total_timesteps      | 1081344   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.2e+14   |\n",
            "|    n_updates            | 5270      |\n",
            "|    policy_gradient_loss | -2.97e-07 |\n",
            "|    reward               | 1080068.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.66e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 529       |\n",
            "|    time_elapsed         | 2589      |\n",
            "|    total_timesteps      | 1083392   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.95e+14  |\n",
            "|    n_updates            | 5280      |\n",
            "|    policy_gradient_loss | -2.84e-07 |\n",
            "|    reward               | 1553385.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.85e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1819412.318224823\n",
            "Sharpe:  0.520005398908802\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 530       |\n",
            "|    time_elapsed         | 2594      |\n",
            "|    total_timesteps      | 1085440   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.4e+14   |\n",
            "|    n_updates            | 5290      |\n",
            "|    policy_gradient_loss | -1.92e-07 |\n",
            "|    reward               | 1552468.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.77e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 531       |\n",
            "|    time_elapsed         | 2598      |\n",
            "|    total_timesteps      | 1087488   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.67e+14  |\n",
            "|    n_updates            | 5300      |\n",
            "|    policy_gradient_loss | -2.88e-07 |\n",
            "|    reward               | 1816611.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.53e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1951169.0660777993\n",
            "Sharpe:  0.5833515373572105\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 532       |\n",
            "|    time_elapsed         | 2603      |\n",
            "|    total_timesteps      | 1089536   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.16e+14  |\n",
            "|    n_updates            | 5310      |\n",
            "|    policy_gradient_loss | -3.54e-08 |\n",
            "|    reward               | 1733967.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.35e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1988578.7846009596\n",
            "Sharpe:  0.6055351578047933\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 533       |\n",
            "|    time_elapsed         | 2608      |\n",
            "|    total_timesteps      | 1091584   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.97e+14  |\n",
            "|    n_updates            | 5320      |\n",
            "|    policy_gradient_loss | -2.06e-07 |\n",
            "|    reward               | 1218362.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.76e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 534       |\n",
            "|    time_elapsed         | 2613      |\n",
            "|    total_timesteps      | 1093632   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.96e+14  |\n",
            "|    n_updates            | 5330      |\n",
            "|    policy_gradient_loss | -1.81e-07 |\n",
            "|    reward               | 1900846.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.81e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2149167.9374584993\n",
            "Sharpe:  0.6731103173759109\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 535       |\n",
            "|    time_elapsed         | 2618      |\n",
            "|    total_timesteps      | 1095680   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.73e+14  |\n",
            "|    n_updates            | 5340      |\n",
            "|    policy_gradient_loss | -1.33e-07 |\n",
            "|    reward               | 1192001.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.45e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 536       |\n",
            "|    time_elapsed         | 2622      |\n",
            "|    total_timesteps      | 1097728   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.97e+14  |\n",
            "|    n_updates            | 5350      |\n",
            "|    policy_gradient_loss | -1.41e-07 |\n",
            "|    reward               | 1995828.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.61e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2191064.3579864865\n",
            "Sharpe:  0.675116945092081\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 537       |\n",
            "|    time_elapsed         | 2627      |\n",
            "|    total_timesteps      | 1099776   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.46e+14  |\n",
            "|    n_updates            | 5360      |\n",
            "|    policy_gradient_loss | -2.75e-07 |\n",
            "|    reward               | 2181268.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.75e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 538       |\n",
            "|    time_elapsed         | 2631      |\n",
            "|    total_timesteps      | 1101824   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.99e+14  |\n",
            "|    n_updates            | 5370      |\n",
            "|    policy_gradient_loss | -2.61e-07 |\n",
            "|    reward               | 2392021.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.98e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2446823.947928891\n",
            "Sharpe:  0.7745297867330642\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 539       |\n",
            "|    time_elapsed         | 2636      |\n",
            "|    total_timesteps      | 1103872   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.06e+14  |\n",
            "|    n_updates            | 5380      |\n",
            "|    policy_gradient_loss | -1.66e-07 |\n",
            "|    reward               | 1607889.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.41e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1806965.9417327838\n",
            "Sharpe:  0.5220611046323375\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 540       |\n",
            "|    time_elapsed         | 2641      |\n",
            "|    total_timesteps      | 1105920   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.8e+14   |\n",
            "|    n_updates            | 5390      |\n",
            "|    policy_gradient_loss | -2.87e-07 |\n",
            "|    reward               | 1342318.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.41e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 541       |\n",
            "|    time_elapsed         | 2645      |\n",
            "|    total_timesteps      | 1107968   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.34e+14  |\n",
            "|    n_updates            | 5400      |\n",
            "|    policy_gradient_loss | -2.27e-07 |\n",
            "|    reward               | 1629351.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.65e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2023767.1322223414\n",
            "Sharpe:  0.6081799286109939\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 542       |\n",
            "|    time_elapsed         | 2650      |\n",
            "|    total_timesteps      | 1110016   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.71e+14  |\n",
            "|    n_updates            | 5410      |\n",
            "|    policy_gradient_loss | -8.75e-08 |\n",
            "|    reward               | 1363483.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.64e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 543       |\n",
            "|    time_elapsed         | 2655      |\n",
            "|    total_timesteps      | 1112064   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.44e+14  |\n",
            "|    n_updates            | 5420      |\n",
            "|    policy_gradient_loss | -1.69e-07 |\n",
            "|    reward               | 1741394.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.6e+14   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1890080.4868474703\n",
            "Sharpe:  0.562808787942734\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 544       |\n",
            "|    time_elapsed         | 2660      |\n",
            "|    total_timesteps      | 1114112   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.66e+14  |\n",
            "|    n_updates            | 5430      |\n",
            "|    policy_gradient_loss | -2.12e-07 |\n",
            "|    reward               | 1587266.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.4e+14   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1689189.3983329749\n",
            "Sharpe:  0.4784333444275899\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 545       |\n",
            "|    time_elapsed         | 2664      |\n",
            "|    total_timesteps      | 1116160   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.68e+14  |\n",
            "|    n_updates            | 5440      |\n",
            "|    policy_gradient_loss | -1.47e-07 |\n",
            "|    reward               | 1063792.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.64e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 546       |\n",
            "|    time_elapsed         | 2669      |\n",
            "|    total_timesteps      | 1118208   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.27e+14  |\n",
            "|    n_updates            | 5450      |\n",
            "|    policy_gradient_loss | -1.51e-07 |\n",
            "|    reward               | 1706341.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.73e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1859413.518666957\n",
            "Sharpe:  0.5428209022380557\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 547       |\n",
            "|    time_elapsed         | 2674      |\n",
            "|    total_timesteps      | 1120256   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.75e+14  |\n",
            "|    n_updates            | 5460      |\n",
            "|    policy_gradient_loss | -2.25e-07 |\n",
            "|    reward               | 1343024.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.41e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 548       |\n",
            "|    time_elapsed         | 2678      |\n",
            "|    total_timesteps      | 1122304   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.41e+14  |\n",
            "|    n_updates            | 5470      |\n",
            "|    policy_gradient_loss | -1.62e-07 |\n",
            "|    reward               | 1783466.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.65e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2028820.3189005984\n",
            "Sharpe:  0.6147964351467525\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 418       |\n",
            "|    iterations           | 549       |\n",
            "|    time_elapsed         | 2683      |\n",
            "|    total_timesteps      | 1124352   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.79e+14  |\n",
            "|    n_updates            | 5480      |\n",
            "|    policy_gradient_loss | -1.42e-07 |\n",
            "|    reward               | 1583434.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.56e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 550       |\n",
            "|    time_elapsed         | 2688      |\n",
            "|    total_timesteps      | 1126400   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.26e+14  |\n",
            "|    n_updates            | 5490      |\n",
            "|    policy_gradient_loss | -5.64e-07 |\n",
            "|    reward               | 1838370.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.47e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2075886.1839530643\n",
            "Sharpe:  0.6156901290352693\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 551       |\n",
            "|    time_elapsed         | 2692      |\n",
            "|    total_timesteps      | 1128448   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.36e+14  |\n",
            "|    n_updates            | 5500      |\n",
            "|    policy_gradient_loss | -9.3e-08  |\n",
            "|    reward               | 1873300.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.78e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2000469.328914444\n",
            "Sharpe:  0.6057266868757439\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 552       |\n",
            "|    time_elapsed         | 2697      |\n",
            "|    total_timesteps      | 1130496   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.43e+14  |\n",
            "|    n_updates            | 5510      |\n",
            "|    policy_gradient_loss | -1.11e-07 |\n",
            "|    reward               | 1103031.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.63e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 553       |\n",
            "|    time_elapsed         | 2702      |\n",
            "|    total_timesteps      | 1132544   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.47e+14  |\n",
            "|    n_updates            | 5520      |\n",
            "|    policy_gradient_loss | -1.72e-07 |\n",
            "|    reward               | 1629096.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.75e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1920633.6849200937\n",
            "Sharpe:  0.5730333251200899\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 554       |\n",
            "|    time_elapsed         | 2707      |\n",
            "|    total_timesteps      | 1134592   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.9e+14   |\n",
            "|    n_updates            | 5530      |\n",
            "|    policy_gradient_loss | -1.1e-07  |\n",
            "|    reward               | 1148241.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.87e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 555       |\n",
            "|    time_elapsed         | 2711      |\n",
            "|    total_timesteps      | 1136640   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.18e+14  |\n",
            "|    n_updates            | 5540      |\n",
            "|    policy_gradient_loss | -2.64e-07 |\n",
            "|    reward               | 1853480.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.19e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2013629.0984604894\n",
            "Sharpe:  0.6176937436861943\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 556       |\n",
            "|    time_elapsed         | 2716      |\n",
            "|    total_timesteps      | 1138688   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.99e+14  |\n",
            "|    n_updates            | 5550      |\n",
            "|    policy_gradient_loss | -2.27e-07 |\n",
            "|    reward               | 1730689.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.91e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 557       |\n",
            "|    time_elapsed         | 2720      |\n",
            "|    total_timesteps      | 1140736   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.24e+14  |\n",
            "|    n_updates            | 5560      |\n",
            "|    policy_gradient_loss | -3.52e-07 |\n",
            "|    reward               | 1960149.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.39e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2052719.371445641\n",
            "Sharpe:  0.6318636307543011\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 558       |\n",
            "|    time_elapsed         | 2725      |\n",
            "|    total_timesteps      | 1142784   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.68e+14  |\n",
            "|    n_updates            | 5570      |\n",
            "|    policy_gradient_loss | -1.4e-07  |\n",
            "|    reward               | 1710813.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.42e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1895879.868702105\n",
            "Sharpe:  0.5613637861604482\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 559       |\n",
            "|    time_elapsed         | 2730      |\n",
            "|    total_timesteps      | 1144832   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.05e+14  |\n",
            "|    n_updates            | 5580      |\n",
            "|    policy_gradient_loss | -1.15e-07 |\n",
            "|    reward               | 1180658.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.97e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 560       |\n",
            "|    time_elapsed         | 2735      |\n",
            "|    total_timesteps      | 1146880   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.49e+14  |\n",
            "|    n_updates            | 5590      |\n",
            "|    policy_gradient_loss | -2.52e-07 |\n",
            "|    reward               | 1615958.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.35e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1913313.063740143\n",
            "Sharpe:  0.5734281605715479\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 561       |\n",
            "|    time_elapsed         | 2739      |\n",
            "|    total_timesteps      | 1148928   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.43e+14  |\n",
            "|    n_updates            | 5600      |\n",
            "|    policy_gradient_loss | -2.34e-07 |\n",
            "|    reward               | 1292097.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.81e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 562       |\n",
            "|    time_elapsed         | 2744      |\n",
            "|    total_timesteps      | 1150976   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.01e+14  |\n",
            "|    n_updates            | 5610      |\n",
            "|    policy_gradient_loss | -1.98e-07 |\n",
            "|    reward               | 1787329.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.09e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1925117.1741589473\n",
            "Sharpe:  0.5769425155837391\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 563       |\n",
            "|    time_elapsed         | 2749      |\n",
            "|    total_timesteps      | 1153024   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.35e+14  |\n",
            "|    n_updates            | 5620      |\n",
            "|    policy_gradient_loss | -4.66e-07 |\n",
            "|    reward               | 1906492.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.89e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2326243.688077755\n",
            "Sharpe:  0.7182682267344134\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 564       |\n",
            "|    time_elapsed         | 2754      |\n",
            "|    total_timesteps      | 1155072   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.15e+14  |\n",
            "|    n_updates            | 5630      |\n",
            "|    policy_gradient_loss | -1.74e-07 |\n",
            "|    reward               | 1047642.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.52e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 565       |\n",
            "|    time_elapsed         | 2758      |\n",
            "|    total_timesteps      | 1157120   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.46e+14  |\n",
            "|    n_updates            | 5640      |\n",
            "|    policy_gradient_loss | -2.19e-08 |\n",
            "|    reward               | 1858569.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.11e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2205121.3026713785\n",
            "Sharpe:  0.6866630633592705\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 566       |\n",
            "|    time_elapsed         | 2763      |\n",
            "|    total_timesteps      | 1159168   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.31e+14  |\n",
            "|    n_updates            | 5650      |\n",
            "|    policy_gradient_loss | -2.36e-07 |\n",
            "|    reward               | 1305570.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.46e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 567       |\n",
            "|    time_elapsed         | 2768      |\n",
            "|    total_timesteps      | 1161216   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.87e+14  |\n",
            "|    n_updates            | 5660      |\n",
            "|    policy_gradient_loss | -3.37e-07 |\n",
            "|    reward               | 1834022.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.36e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2095447.8861205147\n",
            "Sharpe:  0.6437545049814813\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 568       |\n",
            "|    time_elapsed         | 2773      |\n",
            "|    total_timesteps      | 1163264   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.78e+14  |\n",
            "|    n_updates            | 5670      |\n",
            "|    policy_gradient_loss | -5.98e-07 |\n",
            "|    reward               | 1597785.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.48e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 569       |\n",
            "|    time_elapsed         | 2777      |\n",
            "|    total_timesteps      | 1165312   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.48e+14  |\n",
            "|    n_updates            | 5680      |\n",
            "|    policy_gradient_loss | -1.86e-07 |\n",
            "|    reward               | 1922506.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.06e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2102702.2341698986\n",
            "Sharpe:  0.6381290982600955\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 570       |\n",
            "|    time_elapsed         | 2782      |\n",
            "|    total_timesteps      | 1167360   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.88e+14  |\n",
            "|    n_updates            | 5690      |\n",
            "|    policy_gradient_loss | -4.79e-08 |\n",
            "|    reward               | 1969461.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.68e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2219687.8691456798\n",
            "Sharpe:  0.6993387412688861\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 571       |\n",
            "|    time_elapsed         | 2787      |\n",
            "|    total_timesteps      | 1169408   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.23e+14  |\n",
            "|    n_updates            | 5700      |\n",
            "|    policy_gradient_loss | -2.12e-07 |\n",
            "|    reward               | 1102683.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.55e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 572       |\n",
            "|    time_elapsed         | 2791      |\n",
            "|    total_timesteps      | 1171456   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.2e+14   |\n",
            "|    n_updates            | 5710      |\n",
            "|    policy_gradient_loss | -9.12e-08 |\n",
            "|    reward               | 1864384.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.01e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2172898.455671775\n",
            "Sharpe:  0.667985048937348\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 573       |\n",
            "|    time_elapsed         | 2796      |\n",
            "|    total_timesteps      | 1173504   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.66e+14  |\n",
            "|    n_updates            | 5720      |\n",
            "|    policy_gradient_loss | -1.84e-07 |\n",
            "|    reward               | 1194963.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.95e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 574       |\n",
            "|    time_elapsed         | 2801      |\n",
            "|    total_timesteps      | 1175552   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.98e+14  |\n",
            "|    n_updates            | 5730      |\n",
            "|    policy_gradient_loss | -1.89e-07 |\n",
            "|    reward               | 1783080.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.78e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2048014.886314325\n",
            "Sharpe:  0.6258064556473921\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 575       |\n",
            "|    time_elapsed         | 2806      |\n",
            "|    total_timesteps      | 1177600   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.02e+14  |\n",
            "|    n_updates            | 5740      |\n",
            "|    policy_gradient_loss | -1.95e-07 |\n",
            "|    reward               | 1590420.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.95e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 576       |\n",
            "|    time_elapsed         | 2810      |\n",
            "|    total_timesteps      | 1179648   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.18e+14  |\n",
            "|    n_updates            | 5750      |\n",
            "|    policy_gradient_loss | -8.14e-08 |\n",
            "|    reward               | 1829121.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.28e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1957036.8672470143\n",
            "Sharpe:  0.6013508934922408\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 577       |\n",
            "|    time_elapsed         | 2815      |\n",
            "|    total_timesteps      | 1181696   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.16e+14  |\n",
            "|    n_updates            | 5760      |\n",
            "|    policy_gradient_loss | -4.3e-07  |\n",
            "|    reward               | 1858824.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.37e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2144552.6627281373\n",
            "Sharpe:  0.6631293509330681\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 578       |\n",
            "|    time_elapsed         | 2820      |\n",
            "|    total_timesteps      | 1183744   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.93e+14  |\n",
            "|    n_updates            | 5770      |\n",
            "|    policy_gradient_loss | -2.69e-07 |\n",
            "|    reward               | 1205792.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.17e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 579       |\n",
            "|    time_elapsed         | 2824      |\n",
            "|    total_timesteps      | 1185792   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.33e+14  |\n",
            "|    n_updates            | 5780      |\n",
            "|    policy_gradient_loss | -1.77e-07 |\n",
            "|    reward               | 1763187.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.86e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2088164.56848082\n",
            "Sharpe:  0.6279462921602621\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 580       |\n",
            "|    time_elapsed         | 2829      |\n",
            "|    total_timesteps      | 1187840   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.46e+14  |\n",
            "|    n_updates            | 5790      |\n",
            "|    policy_gradient_loss | -1.35e-07 |\n",
            "|    reward               | 1279615.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.47e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 581       |\n",
            "|    time_elapsed         | 2834      |\n",
            "|    total_timesteps      | 1189888   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.47e+14  |\n",
            "|    n_updates            | 5800      |\n",
            "|    policy_gradient_loss | -1.32e-07 |\n",
            "|    reward               | 1869010.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.07e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2029821.2672952171\n",
            "Sharpe:  0.6221586062818873\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 582       |\n",
            "|    time_elapsed         | 2839      |\n",
            "|    total_timesteps      | 1191936   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.97e+14  |\n",
            "|    n_updates            | 5810      |\n",
            "|    policy_gradient_loss | -1.92e-07 |\n",
            "|    reward               | 1678006.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.73e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 583       |\n",
            "|    time_elapsed         | 2844      |\n",
            "|    total_timesteps      | 1193984   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.08e+14  |\n",
            "|    n_updates            | 5820      |\n",
            "|    policy_gradient_loss | -1.27e-07 |\n",
            "|    reward               | 1845888.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.25e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1852680.361762066\n",
            "Sharpe:  0.5651574245494118\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 584       |\n",
            "|    time_elapsed         | 2849      |\n",
            "|    total_timesteps      | 1196032   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.05e+14  |\n",
            "|    n_updates            | 5830      |\n",
            "|    policy_gradient_loss | -1.94e-07 |\n",
            "|    reward               | 2185863.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.09e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2518283.6141763334\n",
            "Sharpe:  0.784862299958177\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 585       |\n",
            "|    time_elapsed         | 2854      |\n",
            "|    total_timesteps      | 1198080   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -2.38e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.17e+14  |\n",
            "|    n_updates            | 5840      |\n",
            "|    policy_gradient_loss | -1.43e-07 |\n",
            "|    reward               | 1237980.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.93e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 586       |\n",
            "|    time_elapsed         | 2858      |\n",
            "|    total_timesteps      | 1200128   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.81e+14  |\n",
            "|    n_updates            | 5850      |\n",
            "|    policy_gradient_loss | -1.02e-07 |\n",
            "|    reward               | 1489037.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.13e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1835114.2969679828\n",
            "Sharpe:  0.530413113153781\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 587       |\n",
            "|    time_elapsed         | 2863      |\n",
            "|    total_timesteps      | 1202176   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.99e+14  |\n",
            "|    n_updates            | 5860      |\n",
            "|    policy_gradient_loss | -1.98e-07 |\n",
            "|    reward               | 1379715.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.96e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 588       |\n",
            "|    time_elapsed         | 2868      |\n",
            "|    total_timesteps      | 1204224   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.87e+14  |\n",
            "|    n_updates            | 5870      |\n",
            "|    policy_gradient_loss | -2.71e-07 |\n",
            "|    reward               | 1758524.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.63e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1863122.4878295537\n",
            "Sharpe:  0.5473884159208839\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 589       |\n",
            "|    time_elapsed         | 2873      |\n",
            "|    total_timesteps      | 1206272   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.71e+14  |\n",
            "|    n_updates            | 5880      |\n",
            "|    policy_gradient_loss | -8.41e-08 |\n",
            "|    reward               | 1694635.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.42e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2203247.4941762025\n",
            "Sharpe:  0.6937979395459238\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 590       |\n",
            "|    time_elapsed         | 2877      |\n",
            "|    total_timesteps      | 1208320   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.09e+14  |\n",
            "|    n_updates            | 5890      |\n",
            "|    policy_gradient_loss | -2.67e-07 |\n",
            "|    reward               | 1069149.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.01e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 591       |\n",
            "|    time_elapsed         | 2882      |\n",
            "|    total_timesteps      | 1210368   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.87e+14  |\n",
            "|    n_updates            | 5900      |\n",
            "|    policy_gradient_loss | -1.79e-07 |\n",
            "|    reward               | 1705935.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.47e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2011797.198298877\n",
            "Sharpe:  0.6097998096276414\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 592       |\n",
            "|    time_elapsed         | 2887      |\n",
            "|    total_timesteps      | 1212416   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.79e+14  |\n",
            "|    n_updates            | 5910      |\n",
            "|    policy_gradient_loss | -1.8e-07  |\n",
            "|    reward               | 1274145.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.43e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 593       |\n",
            "|    time_elapsed         | 2891      |\n",
            "|    total_timesteps      | 1214464   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.67e+14  |\n",
            "|    n_updates            | 5920      |\n",
            "|    policy_gradient_loss | -1.53e-07 |\n",
            "|    reward               | 1688049.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.98e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1992790.367748088\n",
            "Sharpe:  0.5929533504778213\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 594       |\n",
            "|    time_elapsed         | 2896      |\n",
            "|    total_timesteps      | 1216512   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.63e+14  |\n",
            "|    n_updates            | 5930      |\n",
            "|    policy_gradient_loss | -2.44e-07 |\n",
            "|    reward               | 1421929.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.13e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 595       |\n",
            "|    time_elapsed         | 2901      |\n",
            "|    total_timesteps      | 1218560   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.9e+14   |\n",
            "|    n_updates            | 5940      |\n",
            "|    policy_gradient_loss | -3.32e-07 |\n",
            "|    reward               | 1566275.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.88e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1675300.5284961327\n",
            "Sharpe:  0.4581197012820051\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 596       |\n",
            "|    time_elapsed         | 2906      |\n",
            "|    total_timesteps      | 1220608   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 2.38e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.25e+14  |\n",
            "|    n_updates            | 5950      |\n",
            "|    policy_gradient_loss | -2.34e-07 |\n",
            "|    reward               | 2024218.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.51e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2326105.140577281\n",
            "Sharpe:  0.7419113251382714\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 419       |\n",
            "|    iterations           | 597       |\n",
            "|    time_elapsed         | 2911      |\n",
            "|    total_timesteps      | 1222656   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.43e+14  |\n",
            "|    n_updates            | 5960      |\n",
            "|    policy_gradient_loss | -2.82e-07 |\n",
            "|    reward               | 1165647.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.75e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 598       |\n",
            "|    time_elapsed         | 2915      |\n",
            "|    total_timesteps      | 1224704   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.32e+14  |\n",
            "|    n_updates            | 5970      |\n",
            "|    policy_gradient_loss | -2.21e-07 |\n",
            "|    reward               | 1773448.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.05e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1988553.6833365005\n",
            "Sharpe:  0.5935374552599149\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 599       |\n",
            "|    time_elapsed         | 2920      |\n",
            "|    total_timesteps      | 1226752   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.46e+14  |\n",
            "|    n_updates            | 5980      |\n",
            "|    policy_gradient_loss | -3.25e-07 |\n",
            "|    reward               | 1418185.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.7e+14   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 600       |\n",
            "|    time_elapsed         | 2925      |\n",
            "|    total_timesteps      | 1228800   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.66e+14  |\n",
            "|    n_updates            | 5990      |\n",
            "|    policy_gradient_loss | -8.11e-08 |\n",
            "|    reward               | 2038605.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.03e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2238817.8997460003\n",
            "Sharpe:  0.7032792829076003\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 601       |\n",
            "|    time_elapsed         | 2930      |\n",
            "|    total_timesteps      | 1230848   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.93e+14  |\n",
            "|    n_updates            | 6000      |\n",
            "|    policy_gradient_loss | -2.61e-07 |\n",
            "|    reward               | 1657826.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.89e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 602       |\n",
            "|    time_elapsed         | 2934      |\n",
            "|    total_timesteps      | 1232896   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.47e+14  |\n",
            "|    n_updates            | 6010      |\n",
            "|    policy_gradient_loss | -3.15e-07 |\n",
            "|    reward               | 2004680.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.91e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2050727.1766721234\n",
            "Sharpe:  0.6339523742994025\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 603       |\n",
            "|    time_elapsed         | 2939      |\n",
            "|    total_timesteps      | 1234944   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.51e+14  |\n",
            "|    n_updates            | 6020      |\n",
            "|    policy_gradient_loss | -1.27e-07 |\n",
            "|    reward               | 1856702.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.01e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2033529.9621520054\n",
            "Sharpe:  0.6100039162411919\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 604       |\n",
            "|    time_elapsed         | 2944      |\n",
            "|    total_timesteps      | 1236992   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.39e+14  |\n",
            "|    n_updates            | 6030      |\n",
            "|    policy_gradient_loss | -2.71e-07 |\n",
            "|    reward               | 1367235.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.78e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 605       |\n",
            "|    time_elapsed         | 2949      |\n",
            "|    total_timesteps      | 1239040   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.76e+14  |\n",
            "|    n_updates            | 6040      |\n",
            "|    policy_gradient_loss | -4.06e-07 |\n",
            "|    reward               | 1931789.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.09e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2336434.3008570373\n",
            "Sharpe:  0.7302976161669567\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 606       |\n",
            "|    time_elapsed         | 2954      |\n",
            "|    total_timesteps      | 1241088   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.4e+14   |\n",
            "|    n_updates            | 6050      |\n",
            "|    policy_gradient_loss | -9.36e-08 |\n",
            "|    reward               | 1615794.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.72e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 607       |\n",
            "|    time_elapsed         | 2958      |\n",
            "|    total_timesteps      | 1243136   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.93e+14  |\n",
            "|    n_updates            | 6060      |\n",
            "|    policy_gradient_loss | -3.76e-08 |\n",
            "|    reward               | 2132019.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.25e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2302224.470170036\n",
            "Sharpe:  0.7246412687180129\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 608       |\n",
            "|    time_elapsed         | 2963      |\n",
            "|    total_timesteps      | 1245184   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -4.77e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.4e+14   |\n",
            "|    n_updates            | 6070      |\n",
            "|    policy_gradient_loss | -7.33e-08 |\n",
            "|    reward               | 1926397.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.08e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2281442.920830077\n",
            "Sharpe:  0.7046326202418749\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 609       |\n",
            "|    time_elapsed         | 2968      |\n",
            "|    total_timesteps      | 1247232   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.42e+14  |\n",
            "|    n_updates            | 6080      |\n",
            "|    policy_gradient_loss | -4.89e-08 |\n",
            "|    reward               | 1081579.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.27e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 610       |\n",
            "|    time_elapsed         | 2972      |\n",
            "|    total_timesteps      | 1249280   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.33e+14  |\n",
            "|    n_updates            | 6090      |\n",
            "|    policy_gradient_loss | -1.55e-07 |\n",
            "|    reward               | 1802608.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.06e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1986499.0945380963\n",
            "Sharpe:  0.5997399293083238\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 611       |\n",
            "|    time_elapsed         | 2977      |\n",
            "|    total_timesteps      | 1251328   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.97e+14  |\n",
            "|    n_updates            | 6100      |\n",
            "|    policy_gradient_loss | -1.34e-07 |\n",
            "|    reward               | 1400651.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.31e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 612       |\n",
            "|    time_elapsed         | 2982      |\n",
            "|    total_timesteps      | 1253376   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.91e+14  |\n",
            "|    n_updates            | 6110      |\n",
            "|    policy_gradient_loss | -3.01e-07 |\n",
            "|    reward               | 1616514.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.57e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1835409.668982401\n",
            "Sharpe:  0.5260087364721435\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 613       |\n",
            "|    time_elapsed         | 2986      |\n",
            "|    total_timesteps      | 1255424   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.66e+14  |\n",
            "|    n_updates            | 6120      |\n",
            "|    policy_gradient_loss | -1.52e-07 |\n",
            "|    reward               | 1496395.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.27e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 614       |\n",
            "|    time_elapsed         | 2991      |\n",
            "|    total_timesteps      | 1257472   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.91e+14  |\n",
            "|    n_updates            | 6130      |\n",
            "|    policy_gradient_loss | -3.45e-07 |\n",
            "|    reward               | 1805934.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.78e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2053704.2690773285\n",
            "Sharpe:  0.6254478314289766\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 615       |\n",
            "|    time_elapsed         | 2996      |\n",
            "|    total_timesteps      | 1259520   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.54e+14  |\n",
            "|    n_updates            | 6140      |\n",
            "|    policy_gradient_loss | -1.02e-07 |\n",
            "|    reward               | 1711928.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.98e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1904070.5247040289\n",
            "Sharpe:  0.5716629669058382\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 616       |\n",
            "|    time_elapsed         | 3001      |\n",
            "|    total_timesteps      | 1261568   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.82e+14  |\n",
            "|    n_updates            | 6150      |\n",
            "|    policy_gradient_loss | -2.47e-07 |\n",
            "|    reward               | 1093368.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 5.92e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 617       |\n",
            "|    time_elapsed         | 3005      |\n",
            "|    total_timesteps      | 1263616   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.68e+14  |\n",
            "|    n_updates            | 6160      |\n",
            "|    policy_gradient_loss | -2.76e-07 |\n",
            "|    reward               | 1914393.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.2e+14   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2156711.3855433483\n",
            "Sharpe:  0.6575473594570577\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 618       |\n",
            "|    time_elapsed         | 3010      |\n",
            "|    total_timesteps      | 1265664   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.6e+14   |\n",
            "|    n_updates            | 6170      |\n",
            "|    policy_gradient_loss | -1.31e-07 |\n",
            "|    reward               | 1240672.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.18e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 619       |\n",
            "|    time_elapsed         | 3015      |\n",
            "|    total_timesteps      | 1267712   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.82e+14  |\n",
            "|    n_updates            | 6180      |\n",
            "|    policy_gradient_loss | -1.87e-07 |\n",
            "|    reward               | 1648215.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.8e+14   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1873913.9913340958\n",
            "Sharpe:  0.5427197551501143\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 620       |\n",
            "|    time_elapsed         | 3019      |\n",
            "|    total_timesteps      | 1269760   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.82e+14  |\n",
            "|    n_updates            | 6190      |\n",
            "|    policy_gradient_loss | -2.37e-07 |\n",
            "|    reward               | 1765959.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.59e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 621       |\n",
            "|    time_elapsed         | 3024      |\n",
            "|    total_timesteps      | 1271808   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.02e+14  |\n",
            "|    n_updates            | 6200      |\n",
            "|    policy_gradient_loss | -2.56e-07 |\n",
            "|    reward               | 1982457.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.15e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2083068.7270749407\n",
            "Sharpe:  0.6386890791844778\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 622       |\n",
            "|    time_elapsed         | 3029      |\n",
            "|    total_timesteps      | 1273856   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.62e+14  |\n",
            "|    n_updates            | 6210      |\n",
            "|    policy_gradient_loss | -1.73e-09 |\n",
            "|    reward               | 1763861.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 9.22e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2118205.844945054\n",
            "Sharpe:  0.6514602547072278\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 623       |\n",
            "|    time_elapsed         | 3034      |\n",
            "|    total_timesteps      | 1275904   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.04e+14  |\n",
            "|    n_updates            | 6220      |\n",
            "|    policy_gradient_loss | -1.36e-07 |\n",
            "|    reward               | 1167518.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 6.08e+14  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 624       |\n",
            "|    time_elapsed         | 3038      |\n",
            "|    total_timesteps      | 1277952   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.11e+14  |\n",
            "|    n_updates            | 6230      |\n",
            "|    policy_gradient_loss | -4.27e-07 |\n",
            "|    reward               | 1807085.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.39e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2159687.928335328\n",
            "Sharpe:  0.6750735566873881\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 420       |\n",
            "|    iterations           | 625       |\n",
            "|    time_elapsed         | 3043      |\n",
            "|    total_timesteps      | 1280000   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.93     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.8e+14   |\n",
            "|    n_updates            | 6240      |\n",
            "|    policy_gradient_loss | -4.52e-07 |\n",
            "|    reward               | 1440096.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 7.54e+14  |\n",
            "---------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8h4TIhZk9j7"
      },
      "source": [
        "## State, Action, Reward - Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VLnTTODaE5B"
      },
      "source": [
        "## Sample a state\n",
        "data = train.loc[5,:]\n",
        "covs = data['cov_list'].values[0] # only need cov matrix for all 7 \n",
        "\n",
        "# state is the cov matrix of each asset and technical indicators there after\n",
        "state =  np.append(np.array(covs), [data[tech].values.tolist() for tech in config.TECHNICAL_INDICATORS_LIST], axis=0)\n",
        "col_list = list(data.tic) + list(config.TECHNICAL_INDICATORS_LIST)\n",
        "pd.DataFrame(state.T,index=data.tic, columns = col_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfUATeU8aQYG"
      },
      "source": [
        "## Sample an action\n",
        "# action is the portfolio allocation on each day\n",
        "e_train_gym.save_action_memory()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmoy8RwnaEc3"
      },
      "source": [
        "## Sample a reward\n",
        "# reward in this case is the total asset value\n",
        "e_train_gym.asset_memory[-5:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8ZE-wBTxqnV"
      },
      "source": [
        "## Trading\n",
        "Assume that we have $1,000,000 initial capital at 2020-01-01. We use the PPO model to trade the 5 assets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLAZFIrxxlBi"
      },
      "source": [
        "trade = data_split(df,'2020-01-01', '2021-8-31')\n",
        "e_trade_gym = StockPortfolioEnv(df = trade, **env_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjQkUkRxx5r7"
      },
      "source": [
        "trade.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WRRp1R_x7U5"
      },
      "source": [
        "df_daily_return, df_actions = DRLAgent.DRL_prediction(model=trained_ppo,\n",
        "                        environment = e_trade_gym)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WhzzJ6nx_Az"
      },
      "source": [
        "df_daily_return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9eNPNzvyBTI"
      },
      "source": [
        "df_daily_return.to_csv('df_daily_return.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3OWs-iEyhxg"
      },
      "source": [
        "# Backtest Our Strategy\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atxcmy2Xyt7j"
      },
      "source": [
        "from pyfolio import timeseries\n",
        "DRL_strat = convert_daily_return_to_pyfolio_ts(df_daily_return)\n",
        "perf_func = timeseries.perf_stats \n",
        "perf_stats_all = perf_func( returns=DRL_strat, \n",
        "                              factor_returns=DRL_strat, \n",
        "                                positions=None, transactions=None, turnover_denom=\"AGB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQAQ1JPSz-t8"
      },
      "source": [
        "print(\"==============PPO Strategy Stats===========\")\n",
        "perf_stats_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MQi_YjxBp00"
      },
      "source": [
        "---\n",
        "need to create baseline with balanced dragon portfolio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SarzWSXS0wYs"
      },
      "source": [
        "baseline_df = data_split(df, start=df_daily_return.loc[0,'date'], end='2021-8-31')\n",
        "drg_wt = [.1,.2,.1,.2,.1,.2,.1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9wZFrUzagcr"
      },
      "source": [
        "## CREATE DRAGON PORTFOLIO IN ABOVE FORMAT \n",
        "# start from DF\n",
        "def get_drg_baseline(dataframe):\n",
        "  # select relevant columns\n",
        "  data = dataframe[dataframe.columns[:8]]\n",
        "  data = data.groupby(['date','tic']).mean()\n",
        "  # prepare empty dictionary\n",
        "  drg_dict = {'date':[], 'open':[], 'high':[], 'low':[], 'close':[],\\\n",
        "            'volume':[], 'tic':'DRG' ,'day':[]}\n",
        "  # prepare aggregated features\n",
        "  keys = ['open', 'high', 'low', 'close', 'volume']\n",
        "\n",
        "  # for each day attach the weighted sum and the date\n",
        "  for date in dataframe.date.unique():\n",
        "    # filter for date\n",
        "    temp = data.loc[date]  \n",
        "    values = temp[temp.columns[:-1]].mul(drg_wt,axis=0).sum()\n",
        "    day = temp[temp.columns[-1]][0]\n",
        "\n",
        "    # append lists\n",
        "    drg_dict['date'].append(date)\n",
        "    drg_dict['day'].append(day)\n",
        "    for key, value in zip(keys, values):\n",
        "      drg_dict[key].append(value)\n",
        "\n",
        "  # create drg df\n",
        "  dataframe = pd.DataFrame(drg_dict)\n",
        "\n",
        "  return dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHzb1-tn0ClM"
      },
      "source": [
        "#baseline stats\n",
        "print(\"==============Get Baseline Stats===========\")\n",
        "baseline_df = get_drg_baseline(baseline_df)\n",
        "\n",
        "stats = backtest_stats(baseline_df, value_col_name = 'close')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BluYn0-y0d9Q"
      },
      "source": [
        "\n",
        "## BackTestPlot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtUEVb2l0E-W"
      },
      "source": [
        "import pyfolio\n",
        "%matplotlib inline\n",
        "\n",
        "\"\"\"baseline_df = get_baseline(\n",
        "        ticker='^SP500TR', \n",
        "        start = df_daily_return.loc[0,'date'],\n",
        "        end = df_daily_return.loc[len(df_daily_return)-1,'date'])\"\"\"\n",
        "\n",
        "baseline_returns = get_daily_return(baseline_df, value_col_name=\"close\")\n",
        "\n",
        "with pyfolio.plotting.plotting_context(font_scale=1.1):\n",
        "        pyfolio.create_full_tear_sheet(returns = DRL_strat,\n",
        "                                       benchmark_rets=baseline_returns, set_context=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}